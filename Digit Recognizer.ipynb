{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "\n",
    "Kagggle link: https://www.kaggle.com/c/digit-recognizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv(\"all/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seperate train and cross from train data\n",
    "train_frac = 0.9\n",
    "train_data = all_train_data.sample(frac=train_frac, random_state=300)\n",
    "cross_data = all_train_data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split label and pixel\n",
    "y_train = train_data['label']\n",
    "X_train = train_data.drop(labels = [\"label\"], axis = 1) \n",
    "y_cross = cross_data['label']\n",
    "X_cross = cross_data.drop(labels = [\"label\"], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "X_train = X_train / 255\n",
    "X_cross = X_cross / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas to numpy array\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "X_cross = X_cross.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_cross = y_cross.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show one of example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb1827c668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5][:, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, is_training):\n",
    "    w_initializer = tf.variance_scaling_initializer()\n",
    "    b_initializer = tf.zeros_initializer()\n",
    "   \n",
    "    # Convolutional Layer #1 and Pooling Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=X,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=w_initializer,\n",
    "        bias_initializer=b_initializer,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=w_initializer,\n",
    "        bias_initializer=b_initializer,\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 5 * 5 * 64])\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, \n",
    "        units=128, \n",
    "        activation=tf.nn.relu,\n",
    "        kernel_initializer=w_initializer,\n",
    "        bias_initializer=b_initializer\n",
    "    )\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.6, training=is_training)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "<tf.Tensor 'Placeholder:0' shape=(?, 28, 28, 1) dtype=float32>, \n",
      "<tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=int32>, \n",
      "<tf.Tensor 'conv2d/kernel/Initializer/truncated_normal/shape:0' shape=(4,) dtype=int32>, \n",
      "<tf.Tensor 'conv2d/kernel/Initializer/truncated_normal/mean:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'conv2d/kernel/Initializer/truncated_normal/stddev:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'conv2d/kernel/Initializer/truncated_normal/TruncatedNormal:0' shape=(3, 3, 1, 32) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/kernel/Initializer/truncated_normal/mul:0' shape=(3, 3, 1, 32) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/kernel/Initializer/truncated_normal:0' shape=(3, 3, 1, 32) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/kernel:0' shape=(3, 3, 1, 32) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d/kernel/Assign:0' shape=(3, 3, 1, 32) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d/kernel/read:0' shape=(3, 3, 1, 32) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/bias/Initializer/zeros:0' shape=(32,) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/bias:0' shape=(32,) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d/bias/Assign:0' shape=(32,) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d/bias/read:0' shape=(32,) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/dilation_rate:0' shape=(2,) dtype=int32>, \n",
      "<tf.Tensor 'conv2d/Conv2D:0' shape=(?, 26, 26, 32) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/BiasAdd:0' shape=(?, 26, 26, 32) dtype=float32>, \n",
      "<tf.Tensor 'conv2d/Relu:0' shape=(?, 26, 26, 32) dtype=float32>, \n",
      "<tf.Tensor 'max_pooling2d/MaxPool:0' shape=(?, 13, 13, 32) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/kernel/Initializer/truncated_normal/shape:0' shape=(4,) dtype=int32>, \n",
      "<tf.Tensor 'conv2d_1/kernel/Initializer/truncated_normal/mean:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/kernel/Initializer/truncated_normal/stddev:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/kernel/Initializer/truncated_normal/TruncatedNormal:0' shape=(3, 3, 32, 64) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/kernel/Initializer/truncated_normal/mul:0' shape=(3, 3, 32, 64) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/kernel/Initializer/truncated_normal:0' shape=(3, 3, 32, 64) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d_1/kernel/Assign:0' shape=(3, 3, 32, 64) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d_1/kernel/read:0' shape=(3, 3, 32, 64) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/bias/Initializer/zeros:0' shape=(64,) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/bias:0' shape=(64,) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d_1/bias/Assign:0' shape=(64,) dtype=float32_ref>, \n",
      "<tf.Tensor 'conv2d_1/bias/read:0' shape=(64,) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/dilation_rate:0' shape=(2,) dtype=int32>, \n",
      "<tf.Tensor 'conv2d_1/Conv2D:0' shape=(?, 11, 11, 64) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/BiasAdd:0' shape=(?, 11, 11, 64) dtype=float32>, \n",
      "<tf.Tensor 'conv2d_1/Relu:0' shape=(?, 11, 11, 64) dtype=float32>, \n",
      "<tf.Tensor 'max_pooling2d_1/MaxPool:0' shape=(?, 5, 5, 64) dtype=float32>, \n",
      "<tf.Tensor 'Reshape/shape:0' shape=(2,) dtype=int32>, \n",
      "<tf.Tensor 'Reshape:0' shape=(?, 1600) dtype=float32>, \n",
      "<tf.Tensor 'dense/kernel/Initializer/truncated_normal/shape:0' shape=(2,) dtype=int32>, \n",
      "<tf.Tensor 'dense/kernel/Initializer/truncated_normal/mean:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dense/kernel/Initializer/truncated_normal/stddev:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dense/kernel/Initializer/truncated_normal/TruncatedNormal:0' shape=(1600, 128) dtype=float32>, \n",
      "<tf.Tensor 'dense/kernel/Initializer/truncated_normal/mul:0' shape=(1600, 128) dtype=float32>, \n",
      "<tf.Tensor 'dense/kernel/Initializer/truncated_normal:0' shape=(1600, 128) dtype=float32>, \n",
      "<tf.Tensor 'dense/kernel:0' shape=(1600, 128) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense/kernel/Assign:0' shape=(1600, 128) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense/kernel/read:0' shape=(1600, 128) dtype=float32>, \n",
      "<tf.Tensor 'dense/bias/Initializer/zeros:0' shape=(128,) dtype=float32>, \n",
      "<tf.Tensor 'dense/bias:0' shape=(128,) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense/bias/Assign:0' shape=(128,) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense/bias/read:0' shape=(128,) dtype=float32>, \n",
      "<tf.Tensor 'dense/MatMul:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dense/BiasAdd:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dense/Relu:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/keep_prob:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/Shape:0' shape=(2,) dtype=int32>, \n",
      "<tf.Tensor 'dropout/dropout/random_uniform/min:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/random_uniform/max:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/random_uniform/RandomUniform:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/random_uniform/sub:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/random_uniform/mul:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/random_uniform:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/add:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/Floor:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/div:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dropout/dropout/mul:0' shape=(?, 128) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/kernel/Initializer/random_uniform/shape:0' shape=(2,) dtype=int32>, \n",
      "<tf.Tensor 'dense_1/kernel/Initializer/random_uniform/min:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dense_1/kernel/Initializer/random_uniform/max:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dense_1/kernel/Initializer/random_uniform/RandomUniform:0' shape=(128, 10) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/kernel/Initializer/random_uniform/sub:0' shape=() dtype=float32>, \n",
      "<tf.Tensor 'dense_1/kernel/Initializer/random_uniform/mul:0' shape=(128, 10) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/kernel/Initializer/random_uniform:0' shape=(128, 10) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/kernel:0' shape=(128, 10) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense_1/kernel/Assign:0' shape=(128, 10) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense_1/kernel/read:0' shape=(128, 10) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/bias/Initializer/zeros:0' shape=(10,) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/bias:0' shape=(10,) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense_1/bias/Assign:0' shape=(10,) dtype=float32_ref>, \n",
      "<tf.Tensor 'dense_1/bias/read:0' shape=(10,) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/MatMul:0' shape=(?, 10) dtype=float32>, \n",
      "<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 10) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# to see dimension for each layer\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# midel pipe\n",
    "prediction = model(X, is_training=True)\n",
    "print(str(tf.contrib.graph_editor.get_tensors(tf.get_default_graph())).replace('<', '\\n<'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_cross, y_cross, learning_rate, batch_size, epochs_num):\n",
    "    train_data_num, _, _, _ = X_train.shape\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder('float', [None, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    # model pipe\n",
    "    prediction = model(X, is_training=True)\n",
    "    \n",
    "    # train pipe\n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # cross validation pipe\n",
    "    correct = tf.equal(tf.argmax(prediction, 1, output_type=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs_num):\n",
    "        # shuffle data\n",
    "        index = np.random.permutation(train_data_num)\n",
    "        X_train=X_train[index]\n",
    "        y_train=y_train[index]\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        for k in range(math.floor(train_data_num/batch_size)):\n",
    "            mini_batch_X = X_train[k * batch_size : k * batch_size + batch_size]\n",
    "            mini_batch_Y = y_train[k * batch_size : k * batch_size + batch_size]\n",
    "            \n",
    "            _, tc = sess.run([optimizer, cost], feed_dict={X: mini_batch_X, y: mini_batch_Y})\n",
    "            epoch_loss += tc\n",
    "\n",
    "        train_ac = sess.run(accuracy, feed_dict={X: X_train, y: y_train})\n",
    "        cross_ac, cross_loss = sess.run([accuracy, cost], feed_dict={X:X_cross, y:y_cross})\n",
    "        \n",
    "        train_ac = train_ac*100\n",
    "        cross_ac = cross_ac*100\n",
    "        print('Epoch ', epoch+1 , ' / ', epochs_num, ': ')\n",
    "        print('- Train loss: ', epoch_loss, ', Train ac: ', train_ac)\n",
    "        print('- Cross loss: ', cross_loss, ', Cross ac: ', cross_ac)\n",
    "\n",
    "    saver.save(sess, 'ckpt/digit_recog.ckpt')\n",
    "    sess.close()\n",
    "    \n",
    "    return epoch_loss, train_ac, cross_loss, cross_ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose hyperparameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. choose learning  rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- lr:  0.001 ---\n",
      "Epoch  1  /  10 : \n",
      "- Train loss:  118.28529321402311 , Train ac:  95.28042078018188\n",
      "- Cross loss:  0.1679758 , Cross ac:  94.97619271278381\n",
      "Epoch  2  /  10 : \n",
      "- Train loss:  41.300268441438675 , Train ac:  96.56878113746643\n",
      "- Cross loss:  0.1160628 , Cross ac:  96.69047594070435\n",
      "Epoch  3  /  10 : \n",
      "- Train loss:  30.919281600043178 , Train ac:  97.37301468849182\n",
      "- Cross loss:  0.09012888 , Cross ac:  97.47619032859802\n",
      "Epoch  4  /  10 : \n",
      "- Train loss:  25.093676397576928 , Train ac:  97.89153337478638\n",
      "- Cross loss:  0.08245915 , Cross ac:  97.69047498703003\n",
      "Epoch  5  /  10 : \n",
      "- Train loss:  21.289368056692183 , Train ac:  98.26455116271973\n",
      "- Cross loss:  0.07003832 , Cross ac:  97.83333539962769\n",
      "Epoch  6  /  10 : \n",
      "- Train loss:  17.92128860903904 , Train ac:  98.25661182403564\n",
      "- Cross loss:  0.07498747 , Cross ac:  97.97618985176086\n",
      "Epoch  7  /  10 : \n",
      "- Train loss:  16.651686898432672 , Train ac:  98.48941564559937\n",
      "- Cross loss:  0.0703983 , Cross ac:  97.97618985176086\n",
      "Epoch  8  /  10 : \n",
      "- Train loss:  15.390481860376894 , Train ac:  98.57142567634583\n",
      "- Cross loss:  0.0671482 , Cross ac:  98.11905026435852\n",
      "Epoch  9  /  10 : \n",
      "- Train loss:  13.492744039278477 , Train ac:  98.72486591339111\n",
      "- Cross loss:  0.061812934 , Cross ac:  98.30952286720276\n",
      "Epoch  10  /  10 : \n",
      "- Train loss:  12.444050639402121 , Train ac:  98.91534447669983\n",
      "- Cross loss:  0.061648704 , Cross ac:  98.04762005805969\n",
      "--- lr:  0.01 ---\n",
      "Epoch  1  /  10 : \n",
      "- Train loss:  111.49762486666441 , Train ac:  94.0317451953888\n",
      "- Cross loss:  0.19756241 , Cross ac:  93.92856955528259\n",
      "Epoch  2  /  10 : \n",
      "- Train loss:  52.675561279058456 , Train ac:  95.43121457099915\n",
      "- Cross loss:  0.14696202 , Cross ac:  95.52381038665771\n",
      "Epoch  3  /  10 : \n",
      "- Train loss:  46.07343294844031 , Train ac:  96.29100561141968\n",
      "- Cross loss:  0.13912903 , Cross ac:  95.6666648387909\n",
      "Epoch  4  /  10 : \n",
      "- Train loss:  44.195682153105736 , Train ac:  94.99471187591553\n",
      "- Cross loss:  0.16730186 , Cross ac:  94.42856907844543\n",
      "Epoch  5  /  10 : \n",
      "- Train loss:  39.85612620972097 , Train ac:  96.20370268821716\n",
      "- Cross loss:  0.13680096 , Cross ac:  95.71428298950195\n",
      "Epoch  6  /  10 : \n",
      "- Train loss:  39.496556516736746 , Train ac:  96.84656262397766\n",
      "- Cross loss:  0.12264448 , Cross ac:  96.40476107597351\n",
      "Epoch  7  /  10 : \n",
      "- Train loss:  37.72891751024872 , Train ac:  96.3518500328064\n",
      "- Cross loss:  0.14236651 , Cross ac:  95.90476155281067\n",
      "Epoch  8  /  10 : \n",
      "- Train loss:  37.5163579005748 , Train ac:  96.85449600219727\n",
      "- Cross loss:  0.1391378 , Cross ac:  96.1904764175415\n",
      "Epoch  9  /  10 : \n",
      "- Train loss:  34.91127104498446 , Train ac:  96.875661611557\n",
      "- Cross loss:  0.13211346 , Cross ac:  96.04762196540833\n",
      "Epoch  10  /  10 : \n",
      "- Train loss:  35.243180675432086 , Train ac:  96.49999737739563\n",
      "- Cross loss:  0.13698426 , Cross ac:  95.76190710067749\n",
      "--- lr:  0.1 ---\n",
      "Epoch  1  /  10 : \n",
      "- Train loss:  1021.3632190227509 , Train ac:  11.179894208908081\n",
      "- Cross loss:  2.3082972 , Cross ac:  10.904762148857117\n",
      "Epoch  2  /  10 : \n",
      "- Train loss:  680.5298998355865 , Train ac:  11.179894208908081\n",
      "- Cross loss:  2.3055084 , Cross ac:  10.904762148857117\n",
      "Epoch  3  /  10 : \n",
      "- Train loss:  680.9053506851196 , Train ac:  10.343915224075317\n",
      "- Cross loss:  2.3029373 , Cross ac:  10.499999672174454\n",
      "Epoch  4  /  10 : \n",
      "- Train loss:  680.6595709323883 , Train ac:  11.179894208908081\n",
      "- Cross loss:  2.3113704 , Cross ac:  10.904762148857117\n",
      "Epoch  5  /  10 : \n",
      "- Train loss:  680.5725591182709 , Train ac:  11.179894208908081\n",
      "- Cross loss:  2.3078213 , Cross ac:  10.904762148857117\n",
      "Epoch  6  /  10 : \n",
      "- Train loss:  680.4706645011902 , Train ac:  10.544973611831665\n",
      "- Cross loss:  2.309896 , Cross ac:  9.880952537059784\n",
      "Epoch  7  /  10 : \n",
      "- Train loss:  680.8093347549438 , Train ac:  10.343915224075317\n",
      "- Cross loss:  2.3109007 , Cross ac:  10.499999672174454\n",
      "Epoch  8  /  10 : \n",
      "- Train loss:  680.502277135849 , Train ac:  9.695766866207123\n",
      "- Cross loss:  2.3094182 , Cross ac:  9.690476208925247\n",
      "Epoch  9  /  10 : \n",
      "- Train loss:  680.4887573719025 , Train ac:  10.544973611831665\n",
      "- Cross loss:  2.306762 , Cross ac:  9.880952537059784\n",
      "Epoch  10  /  10 : \n",
      "- Train loss:  680.7472629547119 , Train ac:  11.179894208908081\n",
      "- Cross loss:  2.313099 , Cross ac:  10.904762148857117\n",
      "\n",
      "Best learning rate:  0.001  with cross accuracy: 98.04762005805969\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "batch_size = 128\n",
    "epochs_num = 10\n",
    "\n",
    "max_cross_ac = 0\n",
    "best_lr = learning_rate[0]\n",
    "for lr in learning_rate:\n",
    "    print('--- lr: ', lr, '---')\n",
    "    train_loss, train_ac, cross_loss, cross_ac = train(X_train, y_train, X_cross, y_cross, \n",
    "                                                       lr, batch_size, epochs_num)\n",
    "    if cross_ac > max_cross_ac:\n",
    "        max_cross_ac = cross_ac\n",
    "        best_lr = lr\n",
    "\n",
    "print(\"\\nBest learning rate: \", best_lr, ' with cross accuracy:', max_cross_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the best learning rate for cross loss is **0.001** with cross accuracy: 98.04762005805969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. choose batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- batch size:  64  ---\n",
      "Epoch  1  /  10 : \n",
      "- Train loss:  195.9907901994884 , Train ac:  95.96296548843384\n",
      "- Cross loss:  0.13417675 , Cross ac:  95.92857360839844\n",
      "Epoch  2  /  10 : \n",
      "- Train loss:  70.02418467402458 , Train ac:  97.36508131027222\n",
      "- Cross loss:  0.09691779 , Cross ac:  97.09523916244507\n",
      "Epoch  3  /  10 : \n",
      "- Train loss:  51.47557849064469 , Train ac:  97.8518545627594\n",
      "- Cross loss:  0.07777838 , Cross ac:  97.42857217788696\n",
      "Epoch  4  /  10 : \n",
      "- Train loss:  42.16823971341364 , Train ac:  97.76190519332886\n",
      "- Cross loss:  0.08799585 , Cross ac:  97.57142663002014\n",
      "Epoch  5  /  10 : \n",
      "- Train loss:  36.65191896818578 , Train ac:  98.38888645172119\n",
      "- Cross loss:  0.07146958 , Cross ac:  98.00000190734863\n",
      "Epoch  6  /  10 : \n",
      "- Train loss:  31.816332316957414 , Train ac:  98.70370626449585\n",
      "- Cross loss:  0.067367174 , Cross ac:  98.04762005805969\n",
      "Epoch  7  /  10 : \n",
      "- Train loss:  26.522872751695104 , Train ac:  98.68518710136414\n",
      "- Cross loss:  0.0642966 , Cross ac:  98.35714101791382\n",
      "Epoch  8  /  10 : \n",
      "- Train loss:  24.367731804493815 , Train ac:  98.95238280296326\n",
      "- Cross loss:  0.05125171 , Cross ac:  98.64285588264465\n",
      "Epoch  9  /  10 : \n",
      "- Train loss:  22.93704123736825 , Train ac:  99.015873670578\n",
      "- Cross loss:  0.05830011 , Cross ac:  98.40475916862488\n",
      "Epoch  10  /  10 : \n",
      "- Train loss:  19.044197759474628 , Train ac:  98.92857074737549\n",
      "- Cross loss:  0.060153216 , Cross ac:  98.33333492279053\n",
      "--- batch size:  128  ---\n",
      "Epoch  1  /  10 : \n",
      "- Train loss:  113.62791318446398 , Train ac:  95.1375663280487\n",
      "- Cross loss:  0.1693085 , Cross ac:  95.02381086349487\n",
      "Epoch  2  /  10 : \n",
      "- Train loss:  40.012725822627544 , Train ac:  96.75132036209106\n",
      "- Cross loss:  0.10997273 , Cross ac:  96.92857265472412\n",
      "Epoch  3  /  10 : \n",
      "- Train loss:  30.704777332022786 , Train ac:  97.28307127952576\n",
      "- Cross loss:  0.100325994 , Cross ac:  97.02380895614624\n",
      "Epoch  4  /  10 : \n",
      "- Train loss:  26.172820573672652 , Train ac:  97.7830708026886\n",
      "- Cross loss:  0.08391715 , Cross ac:  97.3809540271759\n",
      "Epoch  5  /  10 : \n",
      "- Train loss:  21.149837653152645 , Train ac:  98.15608263015747\n",
      "- Cross loss:  0.07485786 , Cross ac:  97.35714197158813\n",
      "Epoch  6  /  10 : \n",
      "- Train loss:  18.26911415765062 , Train ac:  98.12169075012207\n",
      "- Cross loss:  0.071513146 , Cross ac:  97.97618985176086\n",
      "Epoch  7  /  10 : \n",
      "- Train loss:  16.931448807474226 , Train ac:  98.67724776268005\n",
      "- Cross loss:  0.07287616 , Cross ac:  98.11905026435852\n",
      "Epoch  8  /  10 : \n",
      "- Train loss:  14.733151971362531 , Train ac:  98.46296310424805\n",
      "- Cross loss:  0.06739555 , Cross ac:  98.16666841506958\n",
      "Epoch  9  /  10 : \n",
      "- Train loss:  13.502546024974436 , Train ac:  98.65344166755676\n",
      "- Cross loss:  0.06868779 , Cross ac:  98.2619047164917\n",
      "Epoch  10  /  10 : \n",
      "- Train loss:  11.80103446985595 , Train ac:  98.9047646522522\n",
      "- Cross loss:  0.05543737 , Cross ac:  98.33333492279053\n",
      "--- batch size:  256  ---\n",
      "Epoch  1  /  10 : \n",
      "- Train loss:  68.7681735754013 , Train ac:  94.38889026641846\n",
      "- Cross loss:  0.17940593 , Cross ac:  94.73809599876404\n",
      "Epoch  2  /  10 : \n",
      "- Train loss:  23.1994973346591 , Train ac:  95.8042323589325\n",
      "- Cross loss:  0.13897519 , Cross ac:  95.76190710067749\n",
      "Epoch  3  /  10 : \n",
      "- Train loss:  17.168953485786915 , Train ac:  97.0714271068573\n",
      "- Cross loss:  0.10830586 , Cross ac:  96.7380940914154\n",
      "Epoch  4  /  10 : \n",
      "- Train loss:  13.947271544486284 , Train ac:  97.51058220863342\n",
      "- Cross loss:  0.08992298 , Cross ac:  97.69047498703003\n",
      "Epoch  5  /  10 : \n",
      "- Train loss:  12.287227535620332 , Train ac:  97.64285683631897\n",
      "- Cross loss:  0.081738696 , Cross ac:  97.6190447807312\n",
      "Epoch  6  /  10 : \n",
      "- Train loss:  10.864492448046803 , Train ac:  98.2195794582367\n",
      "- Cross loss:  0.071571924 , Cross ac:  98.00000190734863\n",
      "Epoch  7  /  10 : \n",
      "- Train loss:  9.338103061541915 , Train ac:  97.92592525482178\n",
      "- Cross loss:  0.09036051 , Cross ac:  97.57142663002014\n",
      "Epoch  8  /  10 : \n",
      "- Train loss:  8.855301681905985 , Train ac:  98.3650803565979\n",
      "- Cross loss:  0.06484823 , Cross ac:  98.02380800247192\n",
      "Epoch  9  /  10 : \n",
      "- Train loss:  7.792829042300582 , Train ac:  98.58730435371399\n",
      "- Cross loss:  0.0679669 , Cross ac:  98.19047451019287\n",
      "Epoch  10  /  10 : \n",
      "- Train loss:  7.278593134135008 , Train ac:  98.69047403335571\n",
      "- Cross loss:  0.06733117 , Cross ac:  98.21428656578064\n",
      "\n",
      "Best batch size:  64 , with cross accuracy: 98.33333492279053\n"
     ]
    }
   ],
   "source": [
    "# change batch size\n",
    "learning_rate = 0.001\n",
    "batch_size_list = [64, 128, 256]\n",
    "epochs_num = 10\n",
    "\n",
    "max_cross_ac = 0\n",
    "best_bs = batch_size_list[0]\n",
    "for bs in batch_size_list:\n",
    "    print('--- batch size: ', bs, ' ---')\n",
    "    train_loss, train_ac, cross_loss, cross_ac = train(X_train, y_train, X_cross, y_cross, \n",
    "                                                       learning_rate, bs, epochs_num)\n",
    "    if cross_ac > max_cross_ac:\n",
    "        max_cross_ac = cross_ac\n",
    "        best_bs = bs\n",
    "\n",
    "print(\"\\nBest batch size: \", best_bs, ', with cross accuracy:', max_cross_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the best batch size for cross loss is **64** with cross accuracy: 98.33333492279053\n",
    "\n",
    "(The batch size 128 is also ok with the same cross accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. choose epoch num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  /  20 : \n",
      "- Train loss:  71.58859105408192 , Train ac:  94.27777528762817\n",
      "- Cross loss:  0.1959934 , Cross ac:  93.92856955528259\n",
      "Epoch  2  /  20 : \n",
      "- Train loss:  22.98341851681471 , Train ac:  96.32539749145508\n",
      "- Cross loss:  0.13656352 , Cross ac:  96.21428847312927\n",
      "Epoch  3  /  20 : \n",
      "- Train loss:  16.658662535250187 , Train ac:  96.83068990707397\n",
      "- Cross loss:  0.1174908 , Cross ac:  96.71428799629211\n",
      "Epoch  4  /  20 : \n",
      "- Train loss:  13.932770788669586 , Train ac:  97.58994579315186\n",
      "- Cross loss:  0.09165271 , Cross ac:  97.4047601222992\n",
      "Epoch  5  /  20 : \n",
      "- Train loss:  11.701462026685476 , Train ac:  97.83597588539124\n",
      "- Cross loss:  0.08339448 , Cross ac:  97.54762053489685\n",
      "Epoch  6  /  20 : \n",
      "- Train loss:  10.252482263371348 , Train ac:  98.19047451019287\n",
      "- Cross loss:  0.079214625 , Cross ac:  97.90475964546204\n",
      "Epoch  7  /  20 : \n",
      "- Train loss:  8.836864080280066 , Train ac:  98.25661182403564\n",
      "- Cross loss:  0.06418707 , Cross ac:  97.97618985176086\n",
      "Epoch  8  /  20 : \n",
      "- Train loss:  8.050601959228516 , Train ac:  98.5370397567749\n",
      "- Cross loss:  0.063580446 , Cross ac:  98.09523820877075\n",
      "Epoch  9  /  20 : \n",
      "- Train loss:  7.666507571935654 , Train ac:  98.44973683357239\n",
      "- Cross loss:  0.06088674 , Cross ac:  98.19047451019287\n",
      "Epoch  10  /  20 : \n",
      "- Train loss:  6.907022809609771 , Train ac:  98.68254065513611\n",
      "- Cross loss:  0.061783448 , Cross ac:  98.23809266090393\n",
      "Epoch  11  /  20 : \n",
      "- Train loss:  6.260113223455846 , Train ac:  98.78836274147034\n",
      "- Cross loss:  0.058563277 , Cross ac:  98.30952286720276\n",
      "Epoch  12  /  20 : \n",
      "- Train loss:  5.813939538784325 , Train ac:  98.93651008605957\n",
      "- Cross loss:  0.06068078 , Cross ac:  98.30952286720276\n",
      "Epoch  13  /  20 : \n",
      "- Train loss:  5.820551614277065 , Train ac:  98.91005158424377\n",
      "- Cross loss:  0.06299274 , Cross ac:  98.5952377319336\n",
      "Epoch  14  /  20 : \n",
      "- Train loss:  5.310741845984012 , Train ac:  99.00529384613037\n",
      "- Cross loss:  0.055821825 , Cross ac:  98.57142567634583\n",
      "Epoch  15  /  20 : \n",
      "- Train loss:  4.702702095732093 , Train ac:  98.92857074737549\n",
      "- Cross loss:  0.05790845 , Cross ac:  98.42857122421265\n",
      "Epoch  16  /  20 : \n",
      "- Train loss:  4.697872545104474 , Train ac:  98.85450005531311\n",
      "- Cross loss:  0.065417334 , Cross ac:  98.11905026435852\n",
      "Epoch  17  /  20 : \n",
      "- Train loss:  4.360991762951016 , Train ac:  99.11110997200012\n",
      "- Cross loss:  0.054789234 , Cross ac:  98.50000143051147\n",
      "Epoch  18  /  20 : \n",
      "- Train loss:  4.071997006423771 , Train ac:  99.19312000274658\n",
      "- Cross loss:  0.053867396 , Cross ac:  98.4761893749237\n",
      "Epoch  19  /  20 : \n",
      "- Train loss:  4.019924886990339 , Train ac:  99.24338459968567\n",
      "- Cross loss:  0.060238097 , Cross ac:  98.38095307350159\n",
      "Epoch  20  /  20 : \n",
      "- Train loss:  3.828848159406334 , Train ac:  99.33862686157227\n",
      "- Cross loss:  0.056270897 , Cross ac:  98.35714101791382\n",
      "\n",
      "Cross accuracy: 98.35714101791382\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size_list = 128\n",
    "epochs_num = 20\n",
    "\n",
    "train_loss, train_ac, cross_loss, cross_ac = train(X_train, y_train, X_cross, y_cross, \n",
    "                                                   learning_rate, bs, epochs_num)\n",
    "\n",
    "print('\\nCross accuracy:', cross_ac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look above loss history, maybe 13 epoches is ok for batchsize 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  /  13 : \n",
      "- Train loss:  76.33140078186989 , Train ac:  94.07936334609985\n",
      "- Cross loss:  0.20585127 , Cross ac:  93.92856955528259\n",
      "Epoch  2  /  13 : \n",
      "- Train loss:  25.05654550343752 , Train ac:  95.67460417747498\n",
      "- Cross loss:  0.14550412 , Cross ac:  95.71428298950195\n",
      "Epoch  3  /  13 : \n",
      "- Train loss:  17.761835731565952 , Train ac:  96.92327976226807\n",
      "- Cross loss:  0.11209433 , Cross ac:  96.83333039283752\n",
      "Epoch  4  /  13 : \n",
      "- Train loss:  15.016760770231485 , Train ac:  97.4047601222992\n",
      "- Cross loss:  0.09533734 , Cross ac:  97.2857117652893\n",
      "Epoch  5  /  13 : \n",
      "- Train loss:  12.63373601064086 , Train ac:  97.66402244567871\n",
      "- Cross loss:  0.09395744 , Cross ac:  97.35714197158813\n",
      "Epoch  6  /  13 : \n",
      "- Train loss:  10.82520467042923 , Train ac:  98.0899453163147\n",
      "- Cross loss:  0.072106585 , Cross ac:  97.9285717010498\n",
      "Epoch  7  /  13 : \n",
      "- Train loss:  10.300339573994279 , Train ac:  98.1243371963501\n",
      "- Cross loss:  0.07369041 , Cross ac:  97.64285683631897\n",
      "Epoch  8  /  13 : \n",
      "- Train loss:  8.816265372559428 , Train ac:  98.24073910713196\n",
      "- Cross loss:  0.083184406 , Cross ac:  97.57142663002014\n",
      "Epoch  9  /  13 : \n",
      "- Train loss:  8.347550366073847 , Train ac:  98.57142567634583\n",
      "- Cross loss:  0.065192744 , Cross ac:  98.07142615318298\n",
      "Epoch  10  /  13 : \n",
      "- Train loss:  7.6105510257184505 , Train ac:  98.7063467502594\n",
      "- Cross loss:  0.07026129 , Cross ac:  98.16666841506958\n",
      "Epoch  11  /  13 : \n",
      "- Train loss:  6.6899468544870615 , Train ac:  98.7063467502594\n",
      "- Cross loss:  0.05648816 , Cross ac:  98.42857122421265\n",
      "Epoch  12  /  13 : \n",
      "- Train loss:  6.1589010478928685 , Train ac:  98.78306984901428\n",
      "- Cross loss:  0.04955118 , Cross ac:  98.52380752563477\n",
      "Epoch  13  /  13 : \n",
      "- Train loss:  5.88525475282222 , Train ac:  98.75397086143494\n",
      "- Cross loss:  0.061929133 , Cross ac:  98.19047451019287\n",
      "\n",
      "Cross accuracy: 98.19047451019287\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size_list = 128\n",
    "epochs_num = 13\n",
    "\n",
    "train_loss, train_ac, cross_loss, cross_ac = train(X_train, y_train, X_cross, y_cross, \n",
    "                                                   learning_rate, bs, epochs_num)\n",
    "\n",
    "print('\\nCross accuracy:', cross_ac)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data():\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "    prediction = model(X, is_training=False)\n",
    "    y = tf.argmax(prediction, 1)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    sess= tf.Session()\n",
    "    saver.restore(sess, 'ckpt/digit_recog.ckpt')\n",
    "    result = sess.run(y, feed_dict={X: test_data})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"all/test.csv\")\n",
    "test_data = test_data.values.reshape(-1, 28, 28, 1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_test_data(result, filename):\n",
    "    # output csv\n",
    "    index = [i for i in range(1, len(result)+1)]\n",
    "\n",
    "    r = pd.DataFrame(result, index=index)\n",
    "    r.columns = ['Label']\n",
    "    r.to_csv(filename, index_label='ImageId')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ckpt/digit_recog.ckpt\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivADQf0/pB7h5GeK5esAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = predict_test_data()\n",
    "\n",
    "# show one of result\n",
    "i = 42\n",
    "print(result[i])\n",
    "g = plt.imshow(test_data[i].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output\n",
    "output_test_data(result, \"result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Argumentation\n",
    "\n",
    "Since my best score for testdata is 0.98985 and, I want to try data argumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def train_with_argumentaion(X_train, y_train, X_cross, y_cross, learning_rate, batch_size, epochs_num):\n",
    "    train_data_num, _, _, _ = X_train.shape\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "    y = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    # argumentaion\n",
    "    datagen = ImageDataGenerator(\n",
    "      rotation_range=15,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      zoom_range=0.1)\n",
    "    \n",
    "    # model pipe\n",
    "    prediction = model(X, is_training=True)\n",
    "    \n",
    "    # train pipe\n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # cross validation pipe\n",
    "    correct = tf.equal(tf.argmax(prediction, 1, output_type=tf.int32), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    max_cross_ac = 0\n",
    "    for epoch in range(epochs_num):\n",
    "        # shuffle data\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        batch_num = 0\n",
    "        batch_num_max = math.floor(train_data_num/batch_size)\n",
    "        for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=batch_size):\n",
    "            _, tc = sess.run([optimizer, cost], feed_dict={X: x_batch, y: y_batch})\n",
    "            epoch_loss += tc\n",
    "            batch_num +=1\n",
    "            if batch_num >= batch_num_max:\n",
    "                break\n",
    "\n",
    "        train_ac = sess.run(accuracy, feed_dict={X: X_train, y: y_train})\n",
    "        cross_ac, cross_loss = sess.run([accuracy, cost], feed_dict={X:X_cross, y:y_cross})\n",
    "        \n",
    "        train_ac = train_ac*100\n",
    "        cross_ac = cross_ac*100\n",
    "        print('Epoch ', epoch+1 , ' / ', epochs_num, ': ')\n",
    "        print('- Train loss: ', epoch_loss, ', Train ac: ', train_ac)\n",
    "        print('- Cross loss: ', cross_loss, ', Cross ac: ', cross_ac)\n",
    "\n",
    "    saver.save(sess, 'ckpt/digit_recog.ckpt')\n",
    "    sess.close()\n",
    "    \n",
    "    return epoch_loss, train_ac, cross_loss, cross_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1  /  13 : \n",
      "- Train loss:  204.4436512887478 , Train ac:  94.28571462631226\n",
      "- Cross loss:  0.18660966 , Cross ac:  94.80952620506287\n",
      "Epoch  2  /  13 : \n",
      "- Train loss:  89.4371302574873 , Train ac:  96.16402387619019\n",
      "- Cross loss:  0.115885675 , Cross ac:  96.42857313156128\n",
      "Epoch  3  /  13 : \n",
      "- Train loss:  68.7021341919899 , Train ac:  97.22751379013062\n",
      "- Cross loss:  0.08891035 , Cross ac:  97.42857217788696\n",
      "Epoch  4  /  13 : \n",
      "- Train loss:  56.09951478242874 , Train ac:  96.74338698387146\n",
      "- Cross loss:  0.09676476 , Cross ac:  97.23809361457825\n",
      "Epoch  5  /  13 : \n",
      "- Train loss:  49.5571723356843 , Train ac:  97.61375784873962\n",
      "- Cross loss:  0.07357875 , Cross ac:  98.04762005805969\n",
      "Epoch  6  /  13 : \n",
      "- Train loss:  45.47972438111901 , Train ac:  97.57142663002014\n",
      "- Cross loss:  0.07228143 , Cross ac:  98.04762005805969\n",
      "Epoch  7  /  13 : \n",
      "- Train loss:  40.96763815358281 , Train ac:  97.88095355033875\n",
      "- Cross loss:  0.06333266 , Cross ac:  98.19047451019287\n",
      "Epoch  8  /  13 : \n",
      "- Train loss:  39.396627116948366 , Train ac:  98.07142615318298\n",
      "- Cross loss:  0.059888 , Cross ac:  98.23809266090393\n",
      "Epoch  9  /  13 : \n",
      "- Train loss:  36.2409634552896 , Train ac:  98.21428656578064\n",
      "- Cross loss:  0.057727624 , Cross ac:  98.28571677207947\n",
      "Epoch  10  /  13 : \n",
      "- Train loss:  34.25072286091745 , Train ac:  98.23015928268433\n",
      "- Cross loss:  0.059595328 , Cross ac:  98.38095307350159\n",
      "Epoch  11  /  13 : \n",
      "- Train loss:  32.062802432104945 , Train ac:  98.32010865211487\n",
      "- Cross loss:  0.059703454 , Cross ac:  98.2619047164917\n",
      "Epoch  12  /  13 : \n",
      "- Train loss:  29.967366168275476 , Train ac:  98.49735498428345\n",
      "- Cross loss:  0.049443092 , Cross ac:  98.50000143051147\n",
      "Epoch  13  /  13 : \n",
      "- Train loss:  28.597607959993184 , Train ac:  98.4761893749237\n",
      "- Cross loss:  0.058937944 , Cross ac:  98.45238327980042\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "epochs_num = 13\n",
    "\n",
    "train_loss, train_ac, cross_loss, cross_ac = train_with_argumentaion(X_train, y_train, X_cross, y_cross, \n",
    "                                                                     learning_rate, batch_size, epochs_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ckpt/digit_recog.ckpt\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivADQf0/pB7h5GeK5esAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"all/test.csv\")\n",
    "test_data = test_data.values.reshape(-1, 28, 28, 1) / 255\n",
    "\n",
    "\n",
    "result = predict_test_data()\n",
    "\n",
    "# show one of result\n",
    "i = 42\n",
    "print(result[i])\n",
    "g = plt.imshow(test_data[i].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output\n",
    "output_test_data(result, \"result-argu.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use argumentation, the accuracy reach 0.99100!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
